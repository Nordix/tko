#!/bin/bash
set -e

HERE=$(dirname "$(readlink --canonicalize "$BASH_SOURCE")")
. "$HERE/_env"
. "$HERE/_trap"

not_root

TIMEOUT=180s

function clean_volumes () {
	# If we don't do this, Docker-in-Docker (and thus Kind) will get confused with existing data
	m 'cleaning volumes (via sudo)...'
	sudo rm --recursive --force /tmp/tko-postgresql/* /tmp/tko-docker/*
}

if [ "$1" == -c ]; then
	m 'deleting cluster...'
	kind delete cluster --name=tko || true
	clean_volumes
fi

# if [ ! -d /var/local-path-provisioner ]; then
# 	m 'setting up Kind local path provisioner for "standard" storage class (via sudo)...'
# 	sudo mkdir --parents /var/local-path-provisioner
# 	sudo chown "$SUDO_USER" /var/local-path-provisioner
# fi

if [ "$1" == -d ]; then
	m 'deleting TKO...'
	"$HERE/kubectl-kind" delete --kustomize="$ROOT/assets/kubernetes/" || true

	m 'waiting for TKO deletion...'
	kubectl wait --for=delete deployment/postgresql --timeout="$TIMEOUT"
	kubectl wait --for=delete pod/tko-runner --timeout="$TIMEOUT"
	clean_volumes
	kubectl wait --for=delete namespace/tko --timeout="$TIMEOUT"
	kubectl wait --for=delete apiservice/v1alpha1.tko.nephio.org --timeout="$TIMEOUT"
else
	m 'creating cluster...'
	kind create cluster --config="$ROOT/assets/kubernetes/kind/tko.yaml" || true
fi

m 'deploying TKO...'

"$HERE/kubectl-kind" apply --kustomize="$ROOT/assets/kubernetes/"

m 'waiting for TKO...'

"$HERE/kubectl-kind" wait deployment/postgresql --namespace=tko --for=condition=available --timeout="$TIMEOUT"
"$HERE/kubectl-kind" wait deployment/tko-api --namespace=tko --for=condition=available --timeout="$TIMEOUT"
"$HERE/kubectl-kind" wait deployment/tko-preparer --namespace=tko --for=condition=available --timeout="$TIMEOUT"
"$HERE/kubectl-kind" wait deployment/tko-meta-scheduler --namespace=tko --for=condition=available --timeout="$TIMEOUT"
"$HERE/kubectl-kind" wait pod/tko-runner --namespace=tko --for=condition=ready --timeout="$TIMEOUT"
"$HERE/kubectl-kind" wait apiservice/v1alpha1.tko.nephio.org --for=condition=available --timeout="$TIMEOUT"

m 'deleting workload clusters...'
# (TODO: find out why Kind sometimes reports them as existing despite having cleaned the tko-docker volume;
# could it be related to the cgroup mounting on the host?)

"$HERE/kind-runner" kind delete cluster --name=edge1
"$HERE/kind-runner" kind delete cluster --name=edge2

m 'creating KRM...'

"$HERE/kubectl-kind" apply --filename="$ROOT/examples/kubernetes/templates.yaml"
"$HERE/kubectl-kind" apply --filename="$ROOT/examples/kubernetes/sites.yaml"
"$HERE/kubectl-kind" create --filename="$ROOT/examples/kubernetes/deployments.yaml"

"$HERE/test-scenario" remote "$HERE/tko-kind"
